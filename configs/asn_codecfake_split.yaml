# audioShieldNet/asnet_6/configs/asn_codecfake_split.yaml
# ============================================================
# ASNet on CodecFake (split)
# Deterministic loaders + security-aware curriculum
# ============================================================

ckpt_dir: codecfake_1

log:
  outdir: audioShieldNet/asnet_6/experiments/${ckpt_dir}
  wandb:
    enable: true
    project: audioshieldnet
    entity: xxxxx
    run_name: ${ckpt_dir}

# -------------------------------
# DATA
# -------------------------------
data:
  name: codecfake_split
  sr: 16000
  n_fft: 1024
  hop: 256
  n_mels: 80
  max_secs: 6.0

  root_dir: /scratch/xxxxx/projects/deepfake/dataset/audio/CodecFake
  train_csv: /scratch/xxxxx/projects/deepfake/dataset/audio/CodecFake/combined/CodecFake_train.csv
  val_csv:   /scratch/xxxxx/projects/deepfake/dataset/audio/CodecFake/combined/CodecFake_val.csv
  test_csv:  /scratch/xxxxx/projects/deepfake/dataset/audio/CodecFake/combined/CodecFake_test.csv

  # If you ever want auto_prepare via codecfake_prepare.py:
  auto_prepare: false
  # lists_dir: ...
  # train_list: train.list
  # val_list:   dev.list
  # test_list:  test.list
  # out_dir:    ...

  sampler: uniform
  # sampler: balanced_batch
  # balanced_batch:
  #   real_per_batch: 128
  #   fake_per_batch: 128

  # Optional VAL-based calibration
  # cal_from_val_frac: 0.20
  # cal_exclude_from_val: true

  # Optional TEST-based calibration (disabled by default to avoid leakage)
  # cal_from_test_frac: 0.20
  # cal_exclude_from_test: true

# -------------------------------
# MODEL
# -------------------------------
model:
  name: asnnet_secdual          # TCN+AttnPool dual encoders
  n_mels: 80
  emb: 128
  hidden_ch: 128
  dropout: 0.20
  heads: 1
  n_vocoders: 8
  grl_lambda: 0.2
  tcn_layers: 4
  tcn_dilations: [1, 2, 4, 8]
  return_aux: true

# -------------------------------
# TRAINING
# -------------------------------
train:
  epochs: 100
  batch_size: 256
  lr: 2.0e-4
  weight_decay: 1.0e-4
  grad_clip: 5.0
  seed: 42
  amp: false
  num_workers: 16
  prefetch_factor: 8
  persistent_workers: true
  pin_memory: true
  steps_per_epoch: null

  loss:
    name: balanced_bce             # balanced_bce | focal | asl | logit_adjusted_bce
    use_effective_num: true
    effective_beta: 0.9999

    warmup:
      enable: true
      epochs: 5
      first: focal

    focal:
      gamma: 2.0
      alpha: 0.25

    asl:
      gamma_pos: 0.0
      gamma_neg: 4.0
      clip: 0.05

    logit_adjusted:
      tau: 1.0

  # Security-aware curriculum (delayed + gentle for codec shifts)
  stability_warmup_frac: 0.20
  sam_start_frac:        0.40
  energy_start_frac:     0.50
  ood_start_frac:        0.60
  adv_start_frac:        0.70
  adv_warmup_epochs: 0

  lr_drop_on_switch: 0.30
  best_metric: eer
  best_mode: min
  save_every_epochs: 1
  keep_top_k: 3

# -------------------------------
# OPTIMIZER / SAM / SWA
# -------------------------------
optim:
  use_sam: true
  sam_rho: 0.002                 # softer SAM for CodecFake instability
  scheduler:
    name: cosine
    warmup_steps: 800
    min_lr: 1.0e-6
  swa:
    enable: true
    start_epoch: 0.85            # keep your existing convention

ema:
  use_ema: true
  decay: 0.999

# -------------------------------
# AUGMENTATIONS
# -------------------------------
augs:
  use_specaug: true
  time_mask_T: 40
  time_mask_p: 0.40
  freq_mask_F: 8
  freq_mask_p: 0.40
  add_noise_p: 0.30
  snr_db: [10, 24]

# -------------------------------
# ASNET loss branch
# -------------------------------
asn:
  use_trainer_asn: true
  win_ms: [80, 160]
  hop_ms: 40
  margin: 0.2
  spoof_weight: 0.5
  tv_weight: 0.0
  mel_sample: 16
  max_time_windows: 64
  cons_weight: 0.05

# -------------------------------
# SECURITY & ROBUSTNESS
# -------------------------------
security:
  # ---- Adversarial defense ----
  use_adv: true
  adv_steps: 2
  adv_eps: [0.0005, 0.001, 0.0015, 0.002]
  adv_alpha: 0.0002
  adv_every: 10
  trades_weight: 0.0

  # ---- Energy regularization gate ----
  energy_reg: true
  energy_weight: 1.0e-5

  energy:
    tau_id: -0.10
    lambda_id: 1.0e-5
    warmup_epochs: 10

  # ---- Gentle OOD push (codec-type transforms) ----
  ood_push:
    use: true
    curriculum: true
    types: [mp3, bandstop, lowpass, reverb, bitrate16k]
    tau_target: 0.10
    weight: 5.0e-6

  # ---- Energy triage & conformal abstention ----
  triage:
    T: 1.0
    tau_susp_energy: -0.25
    use_conformal: true
    target_coverage: 0.90
    auto_tau_eval: true
    tau_override: null

# -------------------------------
# EVALUATION SETTINGS
# -------------------------------
eval:
  use_test: false
  threshold: 0.50
  use_config_threshold: false
  csv_threshold_source: f1
  attack: "fgsm"
  save_pred_csv: true
  verbose: true
  use_temperature_scaling: true
  reliability_bins: 15
  ckpt_choose: last   # auto | best | last | topk1 | topk2 | topk3
